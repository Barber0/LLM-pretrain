{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed867fe2-30e7-45b5-b82d-ffc7795b96aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: tokenizers in /root/miniconda3/lib/python3.8/site-packages (0.13.3)\n",
      "Requirement already satisfied: transformers in /root/miniconda3/lib/python3.8/site-packages (4.31.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /root/miniconda3/lib/python3.8/site-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /root/miniconda3/lib/python3.8/site-packages (from transformers) (1.22.0)\n",
      "Requirement already satisfied: requests in /root/miniconda3/lib/python3.8/site-packages (from transformers) (2.28.2)\n",
      "Requirement already satisfied: filelock in /root/miniconda3/lib/python3.8/site-packages (from transformers) (3.10.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /root/miniconda3/lib/python3.8/site-packages (from transformers) (0.3.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /root/miniconda3/lib/python3.8/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/miniconda3/lib/python3.8/site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /root/miniconda3/lib/python3.8/site-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: tqdm>=4.27 in /root/miniconda3/lib/python3.8/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /root/miniconda3/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
      "Requirement already satisfied: fsspec in /root/miniconda3/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/miniconda3/lib/python3.8/site-packages (from requests->transformers) (3.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /root/miniconda3/lib/python3.8/site-packages (from requests->transformers) (1.26.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/miniconda3/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/lib/python3.8/site-packages (from requests->transformers) (2021.5.30)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tokenizers transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4a1a28f-1cf0-43cc-b558-5c1b97c33286",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from utils import prepare_tokenizer\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b46a80d8-7e5e-4b8f-9a15-0bdd3210b3ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tkn, VOCAB_SIZE = prepare_tokenizer('./tokenizer/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa68829b-4ec7-4bd7-b7e1-160c5841893a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from models import SFLLM\n",
    "from data_obj import ModelArgs\n",
    "model = SFLLM(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    pad_token_id=tkn.pad_token_id,\n",
    "    args=ModelArgs(\n",
    "        hidden_states=3200,\n",
    "        n_heads=32,\n",
    "        n_layers=32,\n",
    "        max_len=1024,\n",
    "        ext_factor=1,\n",
    "    )\n",
    ").cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd998195-8527-41d1-815e-1cc50cfb2179",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "chkpt = torch.load('/root/autodl-tmp/sfllm-magic32/main-0_200000.pt', map_location='cpu')\n",
    "load_res = model.load_state_dict(chkpt, strict=False)\n",
    "model.eval()\n",
    "print(load_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2592948f-0755-4f6c-a311-e0874829af77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "def top_k_top_p_filtering(logits, top_k=0, top_p=0.0, filter_value=-float('Inf')):\n",
    "    \"\"\" Filter a distribution of logits using top-k and/or nucleus (top-p) filtering\n",
    "        Args:\n",
    "            logits: logits distribution shape (vocabulary size)\n",
    "            top_k > 0: keep only top k tokens with highest probability (top-k filtering).\n",
    "            top_p > 0.0: keep the top tokens with cumulative probability >= top_p (nucleus filtering).\n",
    "                Nucleus filtering is described in Holtzman et al. (http://arxiv.org/abs/1904.09751)\n",
    "        From: https://gist.github.com/thomwolf/1a5a29f6962089e871b94cbd09daf317\n",
    "    \"\"\"\n",
    "    assert logits.dim() == 1  # batch size 1 for now - could be updated for more but the code would be less clear\n",
    "    top_k = min(top_k, logits.size(-1))  # Safety check\n",
    "    if top_k > 0:\n",
    "        # Remove all tokens with a probability less than the last token of the top-k\n",
    "        indices_to_remove = logits < torch.topk(logits, top_k)[0][..., -1, None]\n",
    "        logits[indices_to_remove] = filter_value\n",
    "\n",
    "    if top_p > 0.0:\n",
    "        sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
    "        cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
    "\n",
    "        # Remove tokens with cumulative probability above the threshold\n",
    "        sorted_indices_to_remove = cumulative_probs > top_p\n",
    "        # Shift the indices to the right to keep also the first token above the threshold\n",
    "        sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
    "        sorted_indices_to_remove[..., 0] = 0\n",
    "\n",
    "        indices_to_remove = sorted_indices[sorted_indices_to_remove]\n",
    "        logits[indices_to_remove] = filter_value\n",
    "    return logits\n",
    "\n",
    "\n",
    "def sample_sequence(model, context, length, tokenizer, min_length=20, temperature=1.0, top_k=30, top_p=0.0, repitition_penalty=1.0,\n",
    "                    device='cpu'):\n",
    "    context = context.long().to(device)\n",
    "    context = context.unsqueeze(0)\n",
    "    inputs = context\n",
    "    \n",
    "    display_period = max(min_length, length // min_length)\n",
    "\n",
    "    output = None\n",
    "    prefix_kv_list = None\n",
    "    with torch.no_grad():\n",
    "        display_num = length - context.size(1)\n",
    "        last_i = display_num - 1\n",
    "        for i in range(display_num):\n",
    "            model_o, prefix_kv_list = model(inputs, prefix_kv_list=prefix_kv_list, generate=True)  # Note: we could also use 'past' with GPT-2/Transfo-XL/XLNet (cached hidden-states)\n",
    "            next_token_logits = model_o[0, -1, :]\n",
    "\n",
    "            if output is not None:\n",
    "                for tmp_id in set(output[0]):\n",
    "                    next_token_logits[tmp_id] /= repitition_penalty\n",
    "\n",
    "            next_token_logits = next_token_logits / temperature\n",
    "            next_token_logits[tkn.bos_token_id] = -float('Inf')\n",
    "\n",
    "            if output is None or output.size(-1) < min_length:\n",
    "                next_token_logits[tkn.eos_token_id] = -float('Inf')\n",
    "                \n",
    "            next_token_logits[tkn.unk_token_id] = -float('Inf')\n",
    "            filtered_logits = top_k_top_p_filtering(next_token_logits, top_k=top_k, top_p=top_p)\n",
    "            next_token = torch.multinomial(F.softmax(filtered_logits, dim=-1), num_samples=1)\n",
    "\n",
    "            if next_token.item() == tokenizer.eos_token_id:\n",
    "                break\n",
    "            \n",
    "            next_token = next_token.unsqueeze(0)\n",
    "            inputs = next_token\n",
    "\n",
    "            if output is None:\n",
    "                output = next_token\n",
    "            else:\n",
    "                output = torch.cat((output, next_token), dim=1)\n",
    "                \n",
    "            if output.size(-1) % display_period == 0 or i >= last_i:\n",
    "                yield output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14b42b7e-0579-4999-a629-10ea05a8c828",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "def answer(model, tokenizer, prompt):\n",
    "    context_tokens = tokenizer(f'{prompt}', return_tensors='pt').input_ids[0]\n",
    "    out_iter = sample_sequence(\n",
    "        model=model, length=1024,\n",
    "        context=context_tokens, \n",
    "        tokenizer=tkn,\n",
    "        temperature=1, \n",
    "        top_k=10, \n",
    "        repitition_penalty=10,\n",
    "        device='cpu'\n",
    "    )\n",
    "    \n",
    "    for out in out_iter:\n",
    "        clear_output()\n",
    "        txt_gen = tkn.decode(out[0])\n",
    "        print(f'\\rAI: {txt_gen.strip()}', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8ccda07-06e4-484b-b61e-7fb5947c0566",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: This post has been updated with information about the 2019 Subject,\n",
      "Review of: The Best Way to Make a plane! (This is my first attempt at making an airplane. If you haven\\'t done so already then please leave me comments!) - I'm sorry that this isns all for your attention as well...I will be posting here shortly but if it doesn&#38;d work out how we should proceed? Please let us know when things are going on and/or what can happen :) Thanks in advance !<br />*~^~~>Picking up some basic plan & design stuff *-=) You may have read \"How To Train An Aircraft\". It seems like every single book contains many parts which make their way into one or two pages.<ul><li id=\"book\" name='Bookings'>You could use any books from these lists because now they’re available</h5></p>\" \\---> <a href=\"#\">The best ways&quot;</b>\\n[Both] :\\$Airport Books# Bloggers>>and Airports Newsletter|http://www..airbasebooksreviewgroupurl=(https:\\/\\.){7}\\.\\./_](); [ ] ... ;-) </div>';} /^\\//\\/@gabrielkhanovic`eidlfewedroup(dot):complimentary textarea guide | PDF version online only • Bookers who wish accessibility by eiSpy®EasyLink technology support EVOLUTIONICAL CONTACT USERNAME PRIMATES TO THE TRAFFICE FOR FREE OF INTERNET CLASS SPEPTANCE AND METHODS ON ANY WHEEL LIFTS WITHIN OTHER THOUGHTON SESSION BY HANKING PRODUCERS OR YOU READ MORE AT $46 + ($£). All other discount deals must go directly toward our dealership within five days after publication.</strong>`|| ^^^]] ~Learning lessons through fun activities such free download >> https:/homepages/?shop=/devices/% % http%-% www\\.thestandsiteartistofindiacoopblogpostparticipantsforfreeArtisticMediaPlaylistPostmediaNewsWritten By JOHNSEN ROSSEFULUCKNOLOGIES · Download Free mpegcast app .mpdf , playlists @journaleruxtvpn ? jessicaoadjustit iphilipsispublishedPublish Date Added June Issue Title Post Type Contact Us On My App Store Follow Up With Your Social Media Stream And Facebook Comment From Other Users About Twitter Bootstrap Reveal How Can We Help Our Children Share Better Than Life Without Being Struggle Into Instagram Video Downloader For YouTube VideosVideo Dashboard Sample Of Photography Stories At Workspace View Photo Album Edit Image Link Embed Code Here > Learner Articles More Info Page Read more … Written Content Warning Check TRACKED LINKS NOT ALLOW COMPLETE SERVICE IS SUBSCRIPTIONS EXPERTIENT AFGITCHANGED EDIT **Read full article** → Printable Text Editor » Click image As…» — Wiktionarum (@wikitablehealthlineon), December   September·Januarie+JulieBerndorf wrote “the greatest gift ever”—one whereby readers learn not just why anyone would want anything beyond simple life without being stuck around alone.” She said she had found her blog useful before asking questions related exclusively via email using HTML tags instead than sending them over HTTP rather easily thanks him.“What do yall think?” That sounds crazy indeed,” writes Rachel Zuckerman ’cause there was still much left unansweredly regarding whether something needed extra care since its original description wasn´ts published anywhere else.* So yeah yes!! But todayâ€™ll hey everyone â�??“It took forever #wonderhowweirdly😉✦️!” – Just another WordPress plugin made possible due diligence between developers including Google Play Music Studio Team Foundation CEOs Michael Vaccarino‘Â – his own site based upon previous posts ‘Google Developments Are Not Already Knowledge Sharing Proper Websites,’ according author Kelseya Kapoor​in India magazine• Growsing media platforms helps create new communities across devices.- He told BBC Today programme host Neil MacCallaghy last night _not true_. One person asked Apple chief Steve Jobson earlier ''when people were talking 'what happens?''. Another replied ``if someone wants help accessing video content,\" adding \"[...]]\"''``He went back later saying thankyou notes weren\"\" \"\"always.\"'''If anybody wanted assistance downloading audio"
     ]
    }
   ],
   "source": [
    "answer(model, tkn, '''Subject: How to make a plane?\n",
    "Content:''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4778eed-a6e0-4578-b056-f1bb28e67208",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
